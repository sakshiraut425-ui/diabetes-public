# Classification Project - Converted from .ipynb to .py

# --- CONSOLIDATED IMPORTS (From Cells 1, 15, 17, 19, 21, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43) ---
from matplotlib import pyplot
from pandas import read_csv
from pandas import set_option
import numpy # Renaming from `from numpy import array` for consistency with notebook context
from pandas.plotting import scatter_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from pickle import dump, load

# --- DATA LOADING AND INITIAL SETUP (From Cells 3, 5) ---
print("--- Data Loading and Initial Setup ---")
filename = 'pima-indians-diabetes.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
# Assuming the CSV file is in the same directory
try:
    data = read_csv(filename, names=names)
except FileNotFoundError:
    print(f"Error: The file '{filename}' was not found. Please ensure it is in the same directory as this script.")
    exit()

# Setup variables used throughout the script
array = data.values
X = array[:, 0:8]
Y = array[:, 8]
seed = 7
test_size = 0.33
scoring = 'accuracy'
kfold = KFold(n_splits=10, random_state=seed, shuffle=True)

# --- DESCRIPTIVE STATS (From Cells 6, 7, 8, 9) ---
print("\n--- Descriptive Statistics ---")

# Data Types for Each Attribute
types = data.dtypes
print("\nData Types:")
print(types)

# Statistical Summary
print("\nStatistical Summary (data.describe()):")
print(data.describe())
# set_option('precision', 3) # Original line commented out in notebook

# Pairwise Pearson correlations
correlations = data.corr(method='pearson')
print("\nPairwise Pearson correlations:")
print(correlations)

# Class proportion
class_counts = data.groupby('class').size()
print("\nClass proportion:")
print(class_counts)

# --- DATA VISUALIZATION (From Cells 11, 12, 13, 15, 17) ---
print("\n--- Data Visualization (Plots will open, close them to continue) ---")

# Univariate Histograms
data.hist(figsize=(12, 8))
# pyplot.show()

# Density Plots
data.plot(kind='density', subplots=True, layout=(3, 3), sharex=False, figsize=(12, 8))
# pyplot.show()

# Box and Whisker Plots
data.plot(kind='box', subplots=True, layout=(3, 3), sharex=False, sharey=False, figsize=(12, 8))
# pyplot.show()

# Correlation Matrix Plot
fig = pyplot.figure(figsize=(10, 8))
ax = fig.add_subplot(111)
cax = ax.matshow(data.corr(), vmin=-1, vmax=1, interpolation='none')
fig.colorbar(cax)
ticks = numpy.arange(0, 9, 1)
ax.set_xticks(ticks)
ax.set_yticks(ticks)
ax.set_xticklabels(names)
ax.set_yticklabels(names)
# pyplot.show()

# Multivaariate Plots: Scatterplot Matrix
scatter_matrix(data, figsize=(15, 15))
# pyplot.show()

# If you uncommented pyplot.show(), they will block execution until closed.
# We'll uncomment one show() at the end to display all plots generated above.
if __name__ == '__main__':
    print("Displaying generated plots now...")
    pyplot.show()
    print("Plots closed, continuing with script execution.")


# --- DATA PRE-PROCESSING (From Cell 19) ---
print("\n--- Data Pre-processing: Standardize Data ---")

# Standardize data
scaler = StandardScaler().fit(X)
rescaledX = scaler.transform(X)

# summarize transformed data
numpy.set_printoptions(precision=3)
# print("First 5 rows of rescaled data:")
# print(rescaledX[0:5,:])


# --- MODEL EVALUATION (Train/Test Split) (From Cell 21) ---
print("\n--- Model Evaluation: Logistic Regression with Train/Test Split ---")

# split data into train and test sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)

# Fit the model on training set
model = LogisticRegression(max_iter=200)
model.fit(X_train, Y_train)

# evaluate the model on the test set
result = model.score(X_test, Y_test)
print("Logistic Regression (Train/Test) Accuracy: %.3f%%" % (result * 100.0))


# --- MODEL EVALUATION (Cross Validation - KFold) (From Cell 23) ---
print("\n--- Model Evaluation: Cross Validation ---")

# Evaluate Logistic Regression using Cross Validation
model_lr = LogisticRegression(max_iter=200)
results_lr = cross_val_score(model_lr, X, Y, cv=kfold, scoring=scoring)
print("Logistic Regression Accuracy (Cross-Val): %.3f%% (%.3f)" % (results_lr.mean() * 100.0, results_lr.std() * 100.0))

# LDA (Linear Discriminant Analysis) (From Cell 25)
model_lda = LinearDiscriminantAnalysis()
results_lda = cross_val_score(model_lda, X, Y, cv=kfold, scoring=scoring)
print("LDA Accuracy (Cross-Val): %.3f%% (%.3f)" % (results_lda.mean() * 100.0, results_lda.std() * 100.0))

# Naive Bayes (From Cell 27)
model_nb = GaussianNB()
results_nb = cross_val_score(model_nb, X, Y, cv=kfold, scoring=scoring)
print("Naive Bayes Accuracy (Cross-Val): %.3f%% (%.3f)" % (results_nb.mean() * 100.0, results_nb.std() * 100.0))

# KNN (KNeighborsClassifier) (From Cell 29)
model_knn = KNeighborsClassifier()
results_knn = cross_val_score(model_knn, X, Y, cv=kfold, scoring=scoring)
print("KNN Accuracy (Cross-Val): %.3f%% (%.3f)" % (results_knn.mean() * 100.0, results_knn.std() * 100.0))

# CART (DecisionTreeClassifier) (From Cell 31)
model_cart = DecisionTreeClassifier()
results_cart = cross_val_score(model_cart, X, Y, cv=kfold, scoring=scoring)
print("CART Accuracy (Cross-Val): %.3f%% (%.3f)" % (results_cart.mean() * 100.0, results_cart.std() * 100.0))

# SVM (SVC) (From Cell 33)
model_svm = SVC()
results_svm = cross_val_score(model_svm, X, Y, cv=kfold, scoring=scoring)
print("SVM Accuracy (Cross-Val): %.3f%% (%.3f)" % (results_svm.mean() * 100.0, results_svm.std() * 100.0))

# Random Forest (From Cell 35)
model_rf = RandomForestClassifier(random_state=seed)
results_rf = cross_val_score(model_rf, X, Y, cv=kfold, scoring=scoring)
print("Random Forest Accuracy (Cross-Val): %.3f%% (%.3f)" % (results_rf.mean() * 100.0, results_rf.std() * 100.0))

# Gradient Boosting (From Cell 37)
model_gb = GradientBoostingClassifier(random_state=seed)
results_gb = cross_val_score(model_gb, X, Y, cv=kfold, scoring=scoring)
print("Gradient Boosting Accuracy (Cross-Val): %.3f%% (%.3f)" % (results_gb.mean() * 100.0, results_gb.std() * 100.0))


# --- ENSEMBLE MODEL (From Cell 39) ---
print("\n--- Ensemble Model: Voting Classifier ---")

# create the sub models
estimators = []
model1 = LogisticRegression(max_iter=200)
estimators.append(('logistic', model1))
model2 = DecisionTreeClassifier()
estimators.append(('cart', model2))
model3 = SVC()
estimators.append(('svm', model3))

# create the ensemble model
ensemble = VotingClassifier(estimators)
results_ensemble = cross_val_score(ensemble, X, Y, cv=kfold)
print("Voting Ensemble Accuracy: %.3f%% (%.3f)" % (results_ensemble.mean() * 100.0, results_ensemble.std() * 100.0))


# --- MODEL TUNING (From Cell 41) ---
print("\n--- Model Tuning: Logistic Regression with GridSearchCV ---")

# Tune Logistic Regression
# Re-standardize data for tuning, as is common practice before applying penalties like L2
scaler = StandardScaler().fit(X)
rescaledX_tuned = scaler.transform(X)

# Tune hyperparameters
solvers = ['newton-cg', 'lbfgs', 'liblinear']
penalty = ['l2']
c_values = [100, 10, 1.0, 0.1, 0.01]
grid = dict(solver=solvers, penalty=penalty, C=c_values)
model_tune = LogisticRegression(max_iter=200)
grid_search = GridSearchCV(estimator=model_tune, param_grid=grid, cv=kfold, scoring='accuracy')
grid_result = grid_search.fit(rescaledX_tuned, Y)

# Summarize results
print("Tuning Results:")
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))


# --- FINALIZE AND SAVE MODEL (From Cell 43) ---
print("\n--- Finalize and Save Model ---")

# Re-split data for final model training/testing
X_train_final, X_test_final, Y_train_final, Y_test_final = train_test_split(X, Y, test_size=0.33, random_state=7)

# Fit the model on 33% (using the original un-tuned Logistic Regression model)
final_model = LogisticRegression(max_iter=200)
final_model.fit(X_train_final, Y_train_final)

# save the model to disk
save_filename = 'finalized_model.sav'
try:
    with open(save_filename, 'wb') as file:
        dump(final_model, file)
    print(f"Model saved to '{save_filename}'")
except Exception as e:
    print(f"Error saving model: {e}")

# some time later...
# load the model from disk
try:
    with open(save_filename, 'rb') as file:
        loaded_model = load(file)
    print(f"Model loaded from '{save_filename}'")

    # evaluate loaded model
    result_loaded = loaded_model.score(X_test_final, Y_test_final)
    print(f"Loaded model score on test set: {result_loaded}")
except Exception as e:
    print(f"Error loading model: {e}")
